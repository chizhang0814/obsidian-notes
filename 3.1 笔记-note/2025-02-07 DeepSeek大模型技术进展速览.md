 （未来技术所人工智能创新中心编撰，DeepSeek R1大模型友情润色）  
**▎核心创新：性能与成本的双突破**  
2024年12月至2025年1月，DeepSeek连续发布V3（通用基座模型，对标GPT-4o）与R1（推理专用模型，对标O1）。其核心技术突破包括：  
- **架构革新**：  
  - **智能分工系统**（MoE）：将模型拆分为多个"专家"模块，推理时按需调用（类似工厂流水线分工，效率提升30%）  
  - **动态聚焦机制**（MLA）：智能筛选关键信息，内存占用降低50%  
  - **多步预测技术**（MTP）：一次生成多段内容，减少重复计算  
- **工程优化**：  
  采用FP8混合精度（算力需求降低40%）与通信优化技术，支持万卡级协同训练  
- **训练方法**：  
  纯强化学习驱动（减少80%人工标注依赖），总训练成本仅550万美元（行业平均1/3）  
**▎成本争议与技术启示**  
- V3宣称550万美元训练成本源于MoE架构创新，但未计入前期研发投入  
- 李飞飞团队"50美元炼出S1模型"实为特定场景优化：利用1000条精选训练数据，基于开源模型Qwen进行微调，数学推理表现突出但未达R1综合能力  
- 技术启示：开源生态+高效微调可降低AI应用门槛  
**▎算力市场趋势**  
- 显卡需求不降反增：Jevons悖论显现（效率提升刺激应用爆发）  
- 推理市场将成主力：智能客服智能助手等实时需求催生算力消耗  
- 国产化突破：DeepSeek已适配昇腾910C/海光DCU，国产芯片推理性能达国际主流水平  
**▎部署指南**  
- 完整版V3（671B参数/720GB）需专业算力支持  
- 本地可部署蒸馏版（1.5B-70B参数）：通过R1生成80万推理数据微调开源模型，7B/8B版本在常规GPU即可运行  
- 内部资源：人工智能创新中心已在北研中已部署R1模型，可通过BATRI局域网安全访问  
**技术注释**  
GPU/TPU/NPU区别：  
- **GPU**：通用并行计算（图像处理转型AI加速）  
- **TPU**（谷歌）：专攻矩阵运算，机器学习效率优化  
- **NPU**（华为等）：神经网络专用架构，能效比提升显著  
（访问入口敬请期待103实验室通知）